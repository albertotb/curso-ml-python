{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio EVO\n",
    "\n",
    "Dado el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import timedelta, date\n",
    "\n",
    "url_evo  = \"https://api.evobanco.com:8443/evobanco/foreign/exchange/v1/rates\"\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "        \n",
    "start_date = date(2020, 1, 1)\n",
    "end_date = date(2020, 1, 2)\n",
    "\n",
    "res = []\n",
    "fecha = []\n",
    "for date in daterange(start_date, end_date):\n",
    "\n",
    "    date_str = date.strftime(\"%Y-%m-%d\")\n",
    "    print(date_str)\n",
    "\n",
    "    payload = {\"cardType\": \"MC\",\n",
    "               \"amount\": 1,\n",
    "               \"sourceCurrencyCode\": 'USD',\n",
    "               \"fxDate\": date_str}\n",
    "\n",
    "    r_evo = requests.post(url_evo, json=payload)\n",
    "\n",
    "    if r_evo.status_code == requests.codes.ok:\n",
    "        d = r_evo.json()\n",
    "        res.append(d['rate'])\n",
    "        fecha.append(d['date'])\n",
    "    \n",
    "    \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Crear un objeto de tipo Serie que contenga la tasa de conversión como los valores y la fecha como índice\n",
    "\n",
    "2. Encontrar los dias con la menor y mayor tasa de cambio\n",
    "\n",
    "3. (Opcional) Escribir el código anterior en una función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-14e6810d317f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfecha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "s = pd.Series(res, index=fecha)\n",
    "print(s.max())\n",
    "print(s.idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio alojamientos\n",
    "\n",
    "1. Leer el fichero \"alojamientos.json\" como un DataFrame de pandas\n",
    "\n",
    "2. Contar cuantos alojamientos hay en cada código postal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aloj = pd.read_json('../data/alojamientos.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aloj['cp'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio numpy\n",
    "\n",
    "Repetir el ejercicio de las notas numpy pero usando `pd.cut()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234)\n",
    "notas = np.random.choice(range(0, 11), size=100)\n",
    "pd.cut(notas, [0, 5, 7, 9, 11], right=False, labels=[\"Suspenso\", \"Aprobado\", \"Notable\", \"Sobresaliente\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1\n",
    "\n",
    "Tenemos las siguientes listas de marcas, modelos y precios en euros de \n",
    "arneses de escalada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marcas  = ['HP', 'HP', 'ASUS', 'Lenovo', 'ASUS', 'ASUS', 'HP',\n",
    "          'Acer', 'Lenovo', 'HP']\n",
    "modelos = ['Envy', 'Pavilion', 'Transformer', 'Ideapad', 'Zenbook', 'Vivobook', '255',\n",
    "           'Aspire', 'Ideapad 530S', 'Stream']\n",
    "precios = [1099.00, 927.48, 199.00, 365.17, 899.00, 599.00, 260.31, 285.09, \n",
    "           699.00, 164.37]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Construir un DataFrame con los datos anteriores.\n",
    "2. Localizar los modelos que tienen un precio menor de 500 euros.\n",
    "3. Crear una nueva columna que contenga el precio original para todos los productos salvo los de la marca HP, a los que se aplicará un descuento del 10%.\n",
    "4. Crea una lista de 10 números aleatorios entre 0 y 50 y añádela al DataFrame en la columna 'Ventas'\n",
    "5. Añade en la columna 'Total' el producto del precio de cada portátil por el número de unidades vendidas ('Ventas')\n",
    "6. Calcular las ventas y ganancias totales\n",
    "7. (Avanzado) Calcular las ventas, ganancias totales y número de productos para cada marca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'marca': marcas, 'modelo': modelos, 'precio': precios})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = np.where(df['marca'] == 'HP', 0.9, 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "df['precio_desc'] = df['precio'] * df['ratio']\n",
    "df['ventas'] = np.random.choice(range(1, 51), size=df['precio'].size)\n",
    "df['ganancias'] = df['ventas'] * df['precio']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ ['ganancias', 'ventas'] ].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2\n",
    "\n",
    "1. Carga en un DataFrame este dataset:\n",
    "https://archive.ics.uci.edu/ml/datasets/Automobile\n",
    "2. Comprueba si tiene datos que faltan y elimina dichas filas\n",
    "3. Obtén la longitud (`length`) y anchuras (`width`) medias por cada categoría de `body-style`\n",
    "4. Analiza el atributo peso (`curb-weight`) y dibuja su histograma\n",
    "5. Analiza cuál es el número de cilindros (`num-of-cylinders`) más frecuente\n",
    "6. Obtén una lista ordenada de las diferentes marcas (`make`) de coches\n",
    "7. Calcula la media del precio (`price`) para los coches agrupados por número de puertas (`num-of-doors`) y tipo de tracción (`engine-location`)\n",
    "8. Selecciona los coches de la marca Toyota y cuyo precio sea mayor que la media\n",
    "9. ¿Son más caros los coches de gas o de diesel (`fuel-type`)? Dibuja un boxplot\n",
    "10. (Avanzado) En lugar de eliminar los datos que faltan complétalos. Si la columna es numérica, complétalos con la media, sino con el valor más frecuente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names = ['make', 'fuel-type', 'num-of-doors', 'body-style', 'engine-location', \n",
    "         'length', 'width', 'curb-weight', 'price']\n",
    "\n",
    "col_idx = [2, 3, 5, 6, 8, 10, 11, 13, 25]\n",
    "\n",
    "autos = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "                    'autos/imports-85.data', header=None, na_values=['?'], \n",
    "                    usecols=col_idx, names=names)\n",
    "\n",
    "autos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.groupby('body-style')[['length', 'width']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "autos['curb-weight'].dropna().plot(kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos['num-of-doors'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(autos['make'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.loc[ (autos['make'] == 'toyota') & (autos['price'] > autos['price'].mean()), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos[['price', 'fuel-type']].boxplot(by='fuel-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_or_mode(s):\n",
    "    \n",
    "    \n",
    "tofill = autos.agg(mean_or_mode)\n",
    "fillnae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def filler(s):\n",
    "    fillna\n",
    "    \n",
    "    fillna\n",
    "    \n",
    "\n",
    "\n",
    "autos.apply(filler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tofill = pd.concat((autos.mean(), autos.select_dtypes(exclude='number').mode().loc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tofill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.fillna(tofill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3\n",
    "\n",
    "1. Carga en un DataFrame este dataset:\n",
    "https://archive.ics.uci.edu/ml/datasets/Census+Income\n",
    "2. Estudia si hay variables como el nivel educativo o el país que influyen en\n",
    "que se tuviese un salario mayor o menor de 50K. Puedes simplemente\n",
    "obtener la cuenta de las veces que sucede una u otra cosa de los\n",
    "diferentes grupos para comenzar, y después utilizar técnicas gráficas, e\n",
    "incluso un contraste de hipótesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4\n",
    "\n",
    "Con el conjunto de datos `weather`:\n",
    "  * Crear una variable 'Month' con el mes de cada observación\n",
    "  * Calcular el número de días que nieva cada mes en porcentaje\n",
    "  * Hacer un gráfico de barras de la variable anterior\n",
    "\n",
    "Con el conjunto de datos `nycity`:\n",
    "  * Seleccionar las columnas 'Complaint Type' y 'Location Type'\n",
    "  * Seleccionar las filas con quejas de ruido (\"Noise\")\n",
    "  * Ver que localización ('Location Type') tiene más quejas de ruido\n",
    "  * Ordenaro de menor a mayor\n",
    "  * Hacer un gráfico de barras del número de quejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "weather = pd.read_csv('../data/weather_2012.csv', parse_dates=['Date/Time'])\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Month'] = weather['Date/Time'].dt.month\n",
    "weather['Day']   = weather['Date/Time'].dt.day\n",
    "weather['Snow']  = weather['Weather'].str.contains('Snow')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "(weather.groupby(['Month', 'Day'])['Snow']\n",
    "        .any()\n",
    "        .groupby('Month')\n",
    "        .mean()\n",
    "        .plot(kind='bar', color='green'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://data.cityofnewyork.us/api/views/qaum-u4fw/'\n",
    "                   'rows.csv?accessType=DOWNLOAD',\n",
    "                   low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_noise = data['Complaint Type'].str.contains('Noise')\n",
    "\n",
    "(data.loc[is_noise, ['Complaint Type', 'Location Type']]\n",
    "     .groupby('Location Type')\n",
    "     .size()\n",
    "     .sort_values()\n",
    "     .plot(kind='bar', color='green'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 5\n",
    "\n",
    "Con el conjunto de datos de las `bikes2016.csv`:\n",
    "  * Repetir el análisis del notebook principal para los dias de la semana\n",
    "\n",
    "Con el fichero `AccidentesBicicletas_2017.csv` (http://datos.madrid.es/portal/site/egob), que contiene información sobre los accidentes de tráfico con implicación de bicicletas en Madrid:\n",
    "  * Leer el fichero en un `DataFrame` de Pandas\n",
    "  * Ver cuántas variables hay y contar los valores que faltan en cada una de ellas\n",
    "  * Ver cual es el distrito con más accidentes\n",
    "  * Hacer un gráfico con el número de accidentes que hay de cada tipo\n",
    "  * Hacer un gráfico de barras con el número de accidentes por mes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 6\n",
    "\n",
    "Con el conjunto de datos `titanic.csv` (https://www.kaggle.com/c/titanic):\n",
    " * Leer los datos en un DataFrame de Pandas\n",
    " * Calcular el porcentaje de pasajeros que sobrevivió\n",
    " * Ver cuantos valores faltan en cada una de las variables (pista .isnull())\n",
    " * Eliminar la variable `cabin`\n",
    " * Completar los valores que faltan en `age` con la mediana del resto\n",
    " * Crear una nueva variable que contenga el número total de parientes incluyendo al pasajero\n",
    " * Crear una nueva variable booleana que sea `True` si el pasajero viajaba solo y `Falso` en caso contrario\n",
    " * Calcular la probabilidad de supervivencia en base al sexo\n",
    " * Extraer de la varible nombre una nueva que sea el título ('Mr', 'Ms', etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/titanic.csv', sep=';', decimal=',')\n",
    "df.head()\n",
    "df.dtypes\n",
    "df['survived'].mean() * 100\n",
    "# df.shape[0] - df.count()\n",
    "df.isnull().mean() * 100\n",
    "df.drop('cabin', axis=1)                 # version 0.20\n",
    "df.drop(columns=['cabin'], inplace=True) # version 0.21\n",
    "df['age'].fillna(value=df['age'].median(), inplace=True)\n",
    "df['total'] = df['sibsp'] + df['parch'] + 1\n",
    "df['alone'] = df['total'] == 1\n",
    "df.loc[df['sex'] == 'male', 'survived'].mean()\n",
    "df.loc[df['sex'] == 'female', 'survived'].mean()\n",
    "df['title'] = df['name'].str.extract(\".*\\ (.*)\\..*\", expand=False)\n",
    "df1 = df.dropna(how='any')\n",
    "print(df1.count())\n",
    "\n",
    "df.groupby([\"sex\", \"pclass\"])['survived'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
