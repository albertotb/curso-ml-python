{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos lineales para clasificación\n",
    "\n",
    "Podemos usar la función de la regresión lineal para intentar ajustar un modelo de clasificación:\n",
    "\n",
    "<img src=https://amueller.github.io/ml-workshop-2-of-4/slides/images/linear_boundary_vector.png width=400>\n",
    "\n",
    "$$\\hat{y}_i = f(x_i) = \\text{sign}\\big(w_0 + w_1x_1 + w_2x_2 + \\dots + w_dx_d\\big)$$\n",
    "\n",
    "Función de pérdida:\n",
    "\n",
    "$$L(y_i, \\hat{y_i}) = \\sum_{i=1}^{n} \\left\\{ \\begin{array}{cc} 0 & \\text{si } y_i = \\hat{y}_i \\\\ 1 & \\text{si } y_i \\neq \\hat{y}_i \\end{array} \\right.$$\n",
    "\n",
    "**Problema**: no podemos calcular derivadas, por tanto no podemos calcular los $w$ que minimizan la pérdida media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística\n",
    "\n",
    "El equivalente a la regresión lineal para problemas de clasificación es la regresión logística. Reemplaza la pérdida zero-uno por una \"aproximación\", la pérdida logística:\n",
    "\n",
    "$$L(y_i, \\hat{y_i}) = \\log(\\exp(-y_i\\hat{y}_i) + 1)$$\n",
    "\n",
    "Comparación con la pérdida 0-1:\n",
    "\n",
    "<img src=../../img/loss_comparison.png width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "blood = fetch_openml('blood-transfusion-service-center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(blood.data, blood.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7165775401069518"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='none')\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prob = pd.DataFrame(lr.predict_proba(X_test), columns=['prob_clase_1', 'prob_clase_2'])\n",
    "prob['clase'] = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row0_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row1_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row2_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row3_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row4_col1 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >prob_clase_1</th>        <th class=\"col_heading level0 col1\" >prob_clase_2</th>        <th class=\"col_heading level0 col2\" >clase</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row0_col0\" class=\"data row0 col0\" >0.751464</td>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row0_col1\" class=\"data row0 col1\" >0.248536</td>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row1_col0\" class=\"data row1 col0\" >0.569721</td>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row1_col1\" class=\"data row1 col1\" >0.430279</td>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row2_col0\" class=\"data row2 col0\" >0.568277</td>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row2_col1\" class=\"data row2 col1\" >0.431723</td>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row3_col0\" class=\"data row3 col0\" >0.576968</td>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row3_col1\" class=\"data row3 col1\" >0.423032</td>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row4_col0\" class=\"data row4 col0\" >0.133358</td>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row4_col1\" class=\"data row4 col1\" >0.866642</td>\n",
       "                        <td id=\"T_930f5b56_a727_11ea_a27f_9d21b2eff5f9row4_col2\" class=\"data row4 col2\" >2</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f11bb3a5910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "prob.head(5).style.apply(highlight_max, subset=['prob_clase_1', 'prob_clase_2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística regularizada\n",
    "\n",
    "Al igual que añadimos un término de regularización a la regresión lineal, podemos añadirlo también a la regresión logística. En este caso no hay clases específicas, sino que hay que ajustar los valores del parámetro `penalty`:\n",
    "\n",
    "   * `penalty=l1`, regularización $l_1$ (como Lasso)\n",
    "   * `penalty=l2`, regularización $l_2$ (como Ridge)\n",
    "   * `penalty=elasticnet`, regularización $l_1$ + regularización $l_2$ (como ElasticNet)\n",
    "   \n",
    "**Ojo**: por defecto la clase `LogisticRegression` incluye regularización $l_2$ (`penalty=l2`)\n",
    "\n",
    "Podemos usar la clase `LogisticRegressionCV` para buscar automáticamente el valor óptimo de los parámetros `C` y `l1_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast.data, breast.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.965034965034965"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986013986013986"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lrcv = LogisticRegressionCV(Cs=10, solver='liblinear')\n",
    "lrcv.fit(X_train_std, y_train)\n",
    "lrcv.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04641589])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de clasificación\n",
    "\n",
    "La mayoría de métricas se pueden derivar de la matriz de confusión:\n",
    "\n",
    "<img src=../../img/confusion_matrix.png width=250>\n",
    "\n",
    " * Accuracy: $\\frac{\\text{TP} + \\text{TN}}{\\text{P} + \\text{N}}$\n",
    " \n",
    " \n",
    " * Sensitivity, recall, TPR: $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$\n",
    "\n",
    "\n",
    " * Specificity, TNR: $\\frac{\\text{TN}}{\\text{TN} + \\text{FP}}$\n",
    "\n",
    "\n",
    " * Precision, PPV: $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$\n",
    "\n",
    "\n",
    " * F1 score: $2\\times \\frac{\\text{PPV} \\times \\text{TPR}}{\\text{PPV} + \\text{TPR}}$\n",
    "\n",
    "Las etiquetas positivo y negativo son arbitrarias, aunque se suelen denominar ejemplos positivos a la clase minoritaria.\n",
    "\n",
    " * Documentación API: [metrics](https://scikit-learn.org/stable/modules/classes.html#classification-metrics)\n",
    " \n",
    " * Guía de usuario: [Metrics and scoring: quantifying the quality of predictions](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n",
    "\n",
    " * [Visualizations with Display Objects](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_display_object_visualization.html#sphx-glr-auto-examples-miscellaneous-plot-display-object-visualization-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real_0</th>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real_1</th>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0  pred_1\n",
       "real_0      26      28\n",
       "real_1      42      47"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "ypred = lr.predict(X_test_std)\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "\n",
    "pd.DataFrame(cm, index=['real_0', 'real_1'], columns=['pred_0', 'pred_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "47\n",
      "28\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(tn)\n",
    "print(tp)\n",
    "print(fp)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problemas de clasificación no balanceados\n",
    "\n",
    "[imbalanced-learn](https://imbalanced-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    576\n",
       "1     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../data/balance-scale.data',  names=['balance', 'var1', 'var2', 'var3', 'var4'])\n",
    "\n",
    "df['balance'] = [1 if b=='B' else 0 for b in df['balance']]\n",
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625, 4)\n",
      "(625,)\n",
      "92.16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       576\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.92       625\n",
      "   macro avg       0.46      0.50      0.48       625\n",
      "weighted avg       0.85      0.92      0.88       625\n",
      "\n",
      "[[576   0]\n",
      " [ 49   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "\n",
    "X = df.drop(columns='balance').values\n",
    "y = df['balance'].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X, y)\n",
    "ypred = model.predict(X)\n",
    "print(model.score(X, y) * 100)\n",
    "\n",
    "print(classification_report(y, ypred, zero_division=0))\n",
    "print(confusion_matrix(y, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "#### Ejercicio 1\n",
    "\n",
    "Carga el conjunto de datos `adult.csv` usando pandas:\n",
    "\n",
    "   * Transforma las variables categóricas usando codificación *one-hot*\n",
    "   \n",
    "   * Escala las variables para que tengan media 0 y desviación 1\n",
    "   \n",
    "   * Ajusta un modelo de regresión logística y visualiza los coeficientes\n",
    "   \n",
    "   * Busca el valor óptimo del parámetro $C$ usando validación cruzada\n",
    "   \n",
    "   * Prueba ahora con regularización `elasticnet` y busca el valor óptimo del parámetro `l1_ratio`\n",
    "   \n",
    "#### Ejercicio 2\n",
    "\n",
    "Carga el conjunto de datos `titanic.csv` usando pandas:\n",
    "\n",
    "   * Eliminar las variables `Cabin` y `Name`\n",
    "\n",
    "   * Completar los valores que faltan en la edad con la media\n",
    "\n",
    "   * Convertir las variables no numéricas en numéricas con `.get_dummies()`\n",
    "   \n",
    "   * Particionar el conjunto en train/test\n",
    "   \n",
    "   * Normalizar las variables para que tengan media 0 y varianza 1\n",
    "   \n",
    "   * Ajustar un modelo de Regresión Logística. Prueba con distintas regularizaciones\n",
    "   \n",
    "   * Realizar un gráfico de los coeficientes\n",
    "   \n",
    "   * Calcular la matriz de confusión, f1-score, precision y recall en el conjunto de test. ¿Como se interpretan estos resultados? ¿Observas algún problema?\n",
    "   \n",
    "   * Buscar los parámetros óptimos del modelo usando validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
