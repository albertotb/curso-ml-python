{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de hiper-parámetros\n",
    "\n",
    "La mayoria de estimadores tienen hiper-parámetros que hay que ajustar para que el rendimiento sea bueno. Por ejemplo ya hemos visto el parámetro $k$ de vecinos próximos:\n",
    "\n",
    "<img src=https://amueller.github.io/ml-workshop-2-of-4/slides/images/knn_boundary_varying_k.png width=500>\n",
    "\n",
    "En la mayoría de estimadores estos hiper-parámetros representan la \"flexibilidad\" del modelo:\n",
    "\n",
    "   * Modelos muy flexibles son capaces de memorizar el conjunto de entrenamiento, pero tendrán un mal rendimiento en el conjunto de test (sobreajuste)\n",
    "   * Modelos poco flexibles no serán capaces de aprender el patrón de los datos, y tendrán un mal rendimiento en general (infraajuste)\n",
    "   \n",
    "Este equilibrio entre sobreajuste e infraajuste se suele representar de manera teórica con gráficos como este:\n",
    "\n",
    "<img src=https://amueller.github.io/ml-workshop-2-of-4/slides/images/overfitting_underfitting_cartoon_full.png width=500>\n",
    "\n",
    "Es importante destacar que no es un gráfico realizado con datos reales, sino que es un esquema de lo que se suele observar en la práctica. Hasta el momento dividíamos nuestros datos en dos conjuntos:\n",
    "\n",
    "   * entrenamiento\n",
    "   * test\n",
    "   \n",
    "<img src=https://amueller.github.io/ml-workshop-2-of-4/slides/images/train_test_split_new.png width=500>\n",
    "\n",
    "Pero el conjunto de test **no** se puede usar para comparar el mismo modelo con distintos hiper-parámetros y elegir el que mejor resultado tenga. El conjunto de test **solo** se usa para dar una estimación del rendimiento final. \n",
    "\n",
    "### Conjunto de validación\n",
    "\n",
    "Por tanto, para ajustar hiper-parámetros vamos a dividir los datos en tres conjuntos:\n",
    "\n",
    "  * entramiento\n",
    "  * test\n",
    "  * validación\n",
    "  \n",
    "<img src=https://amueller.github.io/ml-workshop-2-of-4/slides/images/train_test_validation_split.png width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ds = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(ds.data, ds.target, stratify=ds.target, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, stratify=y_train_val, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 30)\n",
      "(143, 30)\n",
      "(107, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "val_scores = {}\n",
    "for k in (1, 3, 5, 10, 15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    val_scores[k] = knn.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.925234\n",
       "3     0.915888\n",
       "5     0.915888\n",
       "10    0.943925\n",
       "15    0.925234\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "val_series = pd.Series(val_scores)\n",
    "val_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k óptimo: 10\n",
      "acierto entrenamiento: 0.946\n",
      "acierto test: 0.916\n"
     ]
    }
   ],
   "source": [
    "k_best = val_series.idxmax()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k_best)\n",
    "knn.fit(X_train_val, y_train_val)\n",
    "\n",
    "print(f'k óptimo: {k_best}')\n",
    "print(f'acierto entrenamiento: {knn.score(X_train_val, y_train_val):.3f}')\n",
    "print(f'acierto test: {knn.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada\n",
    "\n",
    "Consiste en partir los datos de entrenamiento en varios subconjuntos e ir rotando el conjunto de validación:\n",
    "\n",
    "<img src=../../img/cross_validation_new.png width=500>\n",
    "\n",
    "Ventajas con respecto a tener un único conjunto de validación:\n",
    "\n",
    "   * Más estable\n",
    "   * Se usan todos los datos de entrenamiento para buscar los parámetros óptimos\n",
    "   \n",
    "Desventajas:\n",
    "\n",
    "   * Más lento, hay que ajustar tantos modelos como subconjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = {}\n",
    "for k in (1, 3, 5, 10, 15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_val, y_train_val)\n",
    "    cv_scores[k] = np.mean(cross_val_score(knn, X_train_val, y_train_val, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.924806\n",
       "3     0.938926\n",
       "5     0.943632\n",
       "10    0.941307\n",
       "15    0.934275\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cv = pd.Series(cv_scores)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Búsqueda en rejilla + validación cruzada\n",
    "\n",
    "La estrategia de buscar los hiper-parámetros óptimos calculando el error de validación cruzada para cada valor de los parámetros en una rejilla es bastante habitual.\n",
    "\n",
    "scikit-learn implementa esta estrategia en la clase `GridSearchCV`, que simplifica el proceso anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19])})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors': np.arange(1, 20, 2)}\n",
    "cv = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=10)\n",
    "cv.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.943632</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.941362</td>\n",
       "      <td>0.024084</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.941307</td>\n",
       "      <td>0.018969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.941307</td>\n",
       "      <td>0.015864</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.939037</td>\n",
       "      <td>0.018589</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.938926</td>\n",
       "      <td>0.019061</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.934330</td>\n",
       "      <td>0.020159</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.934275</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.934275</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.924806</td>\n",
       "      <td>0.037955</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2       0.000897      0.000139         0.002183        0.000179   \n",
       "5       0.000796      0.000032         0.002055        0.000091   \n",
       "3       0.000812      0.000038         0.002089        0.000239   \n",
       "4       0.000832      0.000070         0.002156        0.000136   \n",
       "8       0.000818      0.000107         0.002181        0.000172   \n",
       "1       0.000827      0.000044         0.002264        0.000376   \n",
       "9       0.000786      0.000013         0.002094        0.000071   \n",
       "6       0.000784      0.000011         0.002056        0.000115   \n",
       "7       0.000808      0.000063         0.002034        0.000096   \n",
       "0       0.001045      0.000243         0.002775        0.000996   \n",
       "\n",
       "  param_n_neighbors               params  split0_test_score  \\\n",
       "2                 5   {'n_neighbors': 5}           0.930233   \n",
       "5                11  {'n_neighbors': 11}           0.930233   \n",
       "3                 7   {'n_neighbors': 7}           0.930233   \n",
       "4                 9   {'n_neighbors': 9}           0.930233   \n",
       "8                17  {'n_neighbors': 17}           0.930233   \n",
       "1                 3   {'n_neighbors': 3}           0.930233   \n",
       "9                19  {'n_neighbors': 19}           0.930233   \n",
       "6                13  {'n_neighbors': 13}           0.930233   \n",
       "7                15  {'n_neighbors': 15}           0.930233   \n",
       "0                 1   {'n_neighbors': 1}           0.930233   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "2           0.953488           0.953488           0.953488           0.953488   \n",
       "5           0.953488           0.930233           0.953488           0.953488   \n",
       "3           0.953488           0.953488           0.953488           0.953488   \n",
       "4           0.953488           0.930233           0.953488           0.953488   \n",
       "8           0.953488           0.930233           0.953488           0.930233   \n",
       "1           0.930233           0.953488           0.953488           0.953488   \n",
       "9           0.953488           0.930233           0.953488           0.930233   \n",
       "6           0.953488           0.930233           0.953488           0.930233   \n",
       "7           0.953488           0.930233           0.953488           0.930233   \n",
       "0           0.953488           0.906977           0.953488           0.883721   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "2           0.930233           0.928571           0.976190           0.928571   \n",
       "5           0.906977           0.928571           1.000000           0.928571   \n",
       "3           0.906977           0.928571           0.976190           0.928571   \n",
       "4           0.930233           0.928571           0.976190           0.928571   \n",
       "8           0.906977           0.952381           0.976190           0.928571   \n",
       "1           0.930233           0.928571           0.976190           0.904762   \n",
       "9           0.883721           0.952381           0.952381           0.928571   \n",
       "6           0.906977           0.928571           0.952381           0.928571   \n",
       "7           0.906977           0.928571           0.952381           0.928571   \n",
       "0           0.953488           0.880952           1.000000           0.880952   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "2           0.928571         0.943632        0.015774                1  \n",
       "5           0.928571         0.941362        0.024084                2  \n",
       "3           0.928571         0.941307        0.018969                3  \n",
       "4           0.928571         0.941307        0.015864                3  \n",
       "8           0.928571         0.939037        0.018589                5  \n",
       "1           0.928571         0.938926        0.019061                6  \n",
       "9           0.928571         0.934330        0.020159                7  \n",
       "6           0.928571         0.934275        0.013993                8  \n",
       "7           0.928571         0.934275        0.013993                8  \n",
       "0           0.904762         0.924806        0.037955               10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(cv.cv_results_).sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k óptimo: {'n_neighbors': 5}\n",
      "mejor cv score: 0.944\n",
      "acierto test: 0.916\n"
     ]
    }
   ],
   "source": [
    "print(f'k óptimo: {cv.best_params_}')\n",
    "print(f'mejor cv score: {cv.best_score_:.3f}')\n",
    "print(f'acierto test: {cv.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras estrategias de validación cruzada\n",
    "\n",
    "La estrategia anterior se conoce con el nombre de validación cruzada de $k$ hojas o $k$-fold cross-validation. Como hemos visto, consiste en crear $k$ subconjuntos aleatorios de forma aleatoria con probabilidad uniforme.\n",
    "\n",
    "También existen otras estrategias:\n",
    "\n",
    "   1. `StratifiedKFold`, generar los subconjuntos de forma que se mantengan la proporción de las clases (estratificados). Esto es especialmente importante si las clases **no están balanceadas**. En `GridSearchCV` y `cross_val_score` la validación cruzada está **estratificada** por defecto si el estimador es de clasificación\n",
    "   \n",
    "   2. `LeaveOneOut`: validación cruzada de $k$ hojas con $k=1$\n",
    "   \n",
    "   3. `(Stratified)ShuffleSplit`: muestrea el conjunto de test con reemplazamiento\n",
    "   \n",
    "   4. `Repeated(Stratified)KFold`: repite la validación cruzada múltiples veces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validación cruzada en series temporales\n",
    "\n",
    "Para las series temporales no tiene sentido escoger el conjunto de test de manera aleatoria, ya que estamos \"prediciendo\" usando datos del futuro\n",
    " \n",
    "Conjunto de test aleatorio | Conjunto de test estructurado\n",
    "---|---\n",
    "<img src=https://amueller.github.io/ml-workshop-2-of-4/slides/images/time_series2.png style=\"width:100%\"> | <img src=https://amueller.github.io/ml-workshop-2-of-4/slides/images/time_series3.png style=\"width:100%\">\n",
    "\n",
    "La clase `TimeSeriesSplit` realiza una validación cruzada pero manteniendo la estructura temporal:\n",
    "\n",
    "<img src=https://amueller.github.io/ml-workshop-2-of-4/slides/images/time_series_cv.png width=500>\n",
    "\n",
    "De esta forma, si por ejemplo tenemos datos de 1 año:\n",
    "\n",
    "   * *Primera partición*: Enero-Octubre entrenamiento, Noviembre-Diciembre test\n",
    "   * *Segunda partición*: Enero-Agosto entrenamiento, Septiembre-Octubre test\n",
    "   * *Tercera partición*: Enero-Junio entrenamiento, Julio-Agosto test\n",
    "   * etc\n",
    "   \n",
    "Es importante destacar que el conjunto de test siempre tiene el mismo tamaño (2 meses en este caso), pero el conjunto de entrenamiento tiene tamaño variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k óptimo: {'n_neighbors': 7}\n",
      "mejor cv score: 0.936\n",
      "acierto test: 0.923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "param_grid = {'n_neighbors': np.arange(1, 20, 2)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train_val, y_train_val)\n",
    "\n",
    "print(f'k óptimo: {grid.best_params_}')\n",
    "print(f'mejor cv score: {grid.best_score_:.3f}')\n",
    "print(f'acierto test: {grid.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "Con el conjunto de datos de titanic:\n",
    "\n",
    "   1. Preparar los datos de la misma forma que en el notebook `03-missing.ipynb`, imputando los valores que faltan de `age` con la media\n",
    "   \n",
    "   2. Ajustar un modelo `LogisticRegression` y buscar el valor óptimo del parámetro `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
