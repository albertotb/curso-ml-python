{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia de modelos\n",
    "\n",
    "Almacenar los modelos en disco una vez entrenados. El modelo contiene toda la información necesaria para ser usado en producción, es decir, para relizar predicciones sobre nuevos datos.\n",
    "\n",
    "**Importante**: para cargar el modelo es necesaria la misma versión de scikit-learn que se usó para exportar el modelo\n",
    "\n",
    "[Guía de usuario](https://scikit-learn.org/stable/modules/model_persistence.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7406426641094095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7406426641094095"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install joblib\n",
    "import joblib\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "print(lr.score(X, y))\n",
    "\n",
    "joblib.dump(lr, 'model.pkl') \n",
    "\n",
    "lr_new = joblib.load('model.pkl')\n",
    "lr_new.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinación de modelos\n",
    "\n",
    "De manera similar a los métodos de ensemble, combinar la salida de varios modelos puede mejorar de forma notable el rendimiento\n",
    "\n",
    "### Voting\n",
    "\n",
    "Con esta técnica combinamos la predicción de los modelos individuales para generar una predicción final. En el caso de **clasificación** tenemos dos formas de combinar las predicciones:\n",
    "\n",
    "  * `hard voting`, la predicción final se calcula como la clase que predice la mayoría de los modelos individuales\n",
    "  \n",
    "  * `soft voting`, la predicción final se calcula como la clase más probable después de sumar las probabilidades de los modelos individuales. Además, cada modelo puede tener un peso diferente\n",
    "\n",
    "Para **regresión** la predición final se calcula como la media de las predicciones individuales. Cada modelo puede tener un peso distinto, de forma que se calcula la media ponderada.\n",
    "\n",
    "[Voting](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting classifier: 0.986\n",
      "LogisticRegression: 0.958\n",
      "SVC: 0.937\n",
      "RandomForestClassifier: 0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "clf1 = LogisticRegression(solver='liblinear')\n",
    "clf2 = SVC()\n",
    "clf3 = RandomForestClassifier()\n",
    "\n",
    "vot_clf = VotingClassifier(estimators=[('lr', clf1), ('svc', clf2), ('rfc', clf3)], voting='hard')\n",
    "\n",
    "vot_clf.fit(X_train, y_train)\n",
    "print(f'Voting classifier: {vot_clf.score(X_test, y_test):.3f}')\n",
    "\n",
    "for clf in (clf1, clf2, clf3):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f'{clf.__class__.__name__}: {clf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos ajustar los parámetros de los modelos individuales usando validación cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'lr__C': [1.0, 10, 100.0], \n",
    "          'rfc__n_estimators': [20, 200], \n",
    "          'svc__C': [1, 10, 100]}\n",
    "\n",
    "grid = GridSearchCV(estimator=vot_clf, param_grid=params, cv=5)\n",
    "grid = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "\n",
    "Método para combinar modelos. Las predicciones de los modelos individuales se usan como entrada para otro meta-modelo, que aprende a combinarlas (*generalizer* en la figura):\n",
    "\n",
    "<img src=../../img/stacking.png width=600>\n",
    "\n",
    "Es similar al método *voting* con pesos, pero en lugar de estar fijos se aprenden a partir de los datos. Además el meta-modelo podría ser no lineal.\n",
    "\n",
    "[Fuente](https://www.commonlounge.com/discussion/1697ade39ac142988861daff4da7f27d)\n",
    "\n",
    "[Stacking](https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7912865416591925"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "estimators = [('rr', RidgeCV()),\n",
    "              ('svr', SVR()),\n",
    "              ('rfr', RandomForestRegressor())]\n",
    "\n",
    "sr = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
    "sr.fit(X_train, y_train)\n",
    "sr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las clases `VotingClassifier`, `VotingRegressor`, `StackingClassifier` y `StackingRegressor` se pueden usar como cualquier otro modelo. Tienen métodos para predecir y se pueden usar dentro de `GridSearchCV` para buscar los parámetros óptimos de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
